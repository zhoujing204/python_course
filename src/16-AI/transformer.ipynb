{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Paper: Attention is All You Need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google 2017年发布的论文： Attention is all you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![all you need is attention](./img/2024-05-07-09-48-26.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![transformer architecture](./img/2024-05-07-09-51-07.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings -- 将单词表示为向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install gensim\n",
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "model2 = gensim.downloader.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 该模型中的每个向量100个维度\n",
    "import gensim.downloader\n",
    "model = gensim.downloader.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回该模型包括的词汇量\n",
    "len(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![words vectors](./img/2024-05-07-10-14-28.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.50045 , -0.70826 ,  0.55388 ,  0.673   ,  0.22486 ,  0.60281 ,\n",
       "       -0.26194 ,  0.73872 , -0.65383 , -0.21606 , -0.33806 ,  0.24498 ,\n",
       "       -0.51497 ,  0.8568  , -0.37199 , -0.58824 ,  0.30637 , -0.30668 ,\n",
       "       -0.2187  ,  0.78369 , -0.61944 , -0.54925 ,  0.43067 , -0.027348,\n",
       "        0.97574 ,  0.46169 ,  0.11486 , -0.99842 ,  1.0661  , -0.20819 ,\n",
       "        0.53158 ,  0.40922 ,  1.0406  ,  0.24943 ,  0.18709 ,  0.41528 ,\n",
       "       -0.95408 ,  0.36822 , -0.37948 , -0.6802  , -0.14578 , -0.20113 ,\n",
       "        0.17113 , -0.55705 ,  0.7191  ,  0.070014, -0.23637 ,  0.49534 ,\n",
       "        1.1576  , -0.05078 ,  0.25731 , -0.091052,  1.2663  ,  1.1047  ,\n",
       "       -0.51584 , -2.0033  , -0.64821 ,  0.16417 ,  0.32935 ,  0.048484,\n",
       "        0.18997 ,  0.66116 ,  0.080882,  0.3364  ,  0.22758 ,  0.1462  ,\n",
       "       -0.51005 ,  0.63777 ,  0.47299 , -0.3282  ,  0.083899, -0.78547 ,\n",
       "        0.099148,  0.039176,  0.27893 ,  0.11747 ,  0.57862 ,  0.043639,\n",
       "       -0.15965 , -0.35304 , -0.048965, -0.32461 ,  1.4981  ,  0.58138 ,\n",
       "       -1.132   , -0.60673 , -0.37505 , -1.1813  ,  0.80117 , -0.50014 ,\n",
       "       -0.16574 , -0.70584 ,  0.43012 ,  0.51051 , -0.8033  , -0.66572 ,\n",
       "       -0.63717 , -0.36032 ,  0.13347 , -0.56075 ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'glove-wiki-gigaword-100'模型每个单词的向量长度为100\n",
    "# GPT3 的向量长度是12,288\n",
    "\n",
    "model['queen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![queen embedding](./img/2024-05-07-09-56-57.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 所有的词的向量都是通过大量语料训练学习得来的\n",
    "- 向量的维度表达了单词的语义信息\n",
    "- 但是每个维度的语义信息都是模糊的，没有准确定义的\n",
    "- 将单词转换为向量后，可以进行向量的运算，可以寻找：\n",
    "  - 最接近的词\n",
    "  - 最不接近的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('towers', 0.8470372557640076),\n",
       " ('building', 0.725898027420044),\n",
       " ('dome', 0.6875219345092773),\n",
       " ('spire', 0.6807529926300049),\n",
       " ('gate', 0.671362578868866),\n",
       " ('skyscraper', 0.6699519753456116),\n",
       " ('roof', 0.6561244130134583),\n",
       " ('walls', 0.6556639075279236),\n",
       " ('built', 0.6550073623657227),\n",
       " ('buildings', 0.6522013545036316)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tower 的近义词\n",
    "\n",
    "import numpy as np\n",
    "model.most_similar('tower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![similar words](./img/2024-05-07-10-18-58.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queen 的最不相似的词\n",
    "\n",
    "model.most_similar(negative=['queen'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![word vectors operation](./img/2024-05-07-10-29-36.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7698540687561035),\n",
       " ('monarch', 0.6843381524085999),\n",
       " ('throne', 0.6755736470222473),\n",
       " ('daughter', 0.6594556570053101),\n",
       " ('princess', 0.6520534157752991),\n",
       " ('prince', 0.6517034769058228),\n",
       " ('elizabeth', 0.6464517712593079),\n",
       " ('mother', 0.631171703338623),\n",
       " ('emperor', 0.6106470823287964),\n",
       " ('wife', 0.6098655462265015)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# woman + king - man ~= queen\n",
    "\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![queen vector](./img/2024-05-07-10-33-42.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('enjoy', 0.4552291929721832),\n",
       " ('chance', 0.4535176753997803),\n",
       " ('ready', 0.45224252343177795),\n",
       " ('opportunity', 0.4434261918067932),\n",
       " ('excellent', 0.4415234923362732),\n",
       " ('free', 0.44127118587493896),\n",
       " ('maintain', 0.440281480550766),\n",
       " ('comfortable', 0.4352276027202606),\n",
       " ('healthy', 0.43348386883735657),\n",
       " ('better', 0.43163517117500305)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# good + happy - bad - sad ~= ?\n",
    "\n",
    "model.most_similar(positive=['good', 'happy'], negative=['bad', 'sad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何计算两个向量之间的相似度？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dot product](./img/2024-05-07-10-50-24.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![negative similar](./img/2024-05-07-10-51-33.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings向量的局限性：\n",
    "\n",
    "- 每个单词通常会有多个不同的含义，都包含在了一个向量中\n",
    "- 缺乏上下文信息，无法区分不同的含义\n",
    "- 例如：\n",
    "  - `apple`\n",
    "    - 可能是水果，也可能是苹果公司\n",
    "  - `python`\n",
    "    - 可能是一种动物，也可能是一种编程语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention机制使得模型可以关注输入序列中不同位置的不同部分，从而更好地捕捉上下文信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Attention Mechanism](./img/2024-05-07-11-08-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![contextualized-embedding](./img/2024-05-07-11-16-05.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
